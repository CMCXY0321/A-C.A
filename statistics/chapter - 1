#### 实现统计学习的步骤
- 得到一个有限的训练数据集合
- 确定包含所有可能的模型的假设空间，即学习模型的集合
- 确定模型选择的准则，学习的策略
- 实现求解最优模型的算法，学习算法
- 通过学习方法选择最优模型
- 利用学习的最优模型对新数据进行预测或分析

#### 监督学习
方法=模型+策略+算法

##### 模型
统计学习首要考虑的问题是学习什么样的模型.
在监督学习过程中，模型是所要学习的条件概率分布或者决策函数.
模型的假设空间（hypothesis space）包含所有可能的条件概率分布或者决策函数.

```
F={f|Y=f(X)}
```

##### 策略
有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优模型.
- 损失函数和风险函数
- 经验风险最小化和决策风险最小化

#### 算法
算法是指学习模型的具体计算方法. 统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型.

##### 模型评估与模型选择
统计学习的目的是使学到的模型不仅对已知数据而且对未知数据都能有很好的预测能力.
当损失函数给定时，基于损失模型的函数的模型的训练误差（training error）和模型的测试误差（test error）就自然成为学习方法的评估的标准.

##### 过拟合与模型选择
当假设空间含有不同复杂度的模型时，就要面临模型选择的问题（model selection）.

#### 正则化与交叉验证

##### 正则化
模型选择的经典方法是正则化. 正则化是结构风险的最小化策略的实现，是在经典风险上加上一个正则化.

##### 交叉验证
另一种常用的模型选择方法是交叉验证.

- 简单交叉验证
- S折交叉验证
- 留一交叉验证

#### 泛化能力

##### 泛化误差
学习方法的泛化能力是指由该方法学习到的模型对未知数据的预测能力，是学习方法上的本质实现.
现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力.

##### 泛化误差上界
学习方法的泛化能力分析往往是通过研究误差上界进行，简称泛化误差上界.

##### 生成模型与判别模式
监督学习的任务就是学习一个模型，应用这一个模型，对给定的输入预测相应的输出.

##### 分类问题
分类是监督学习的一个核心问题. 在监督学习中，当输出变量Y取有限个离散值时，预测问题变成分类问题.

#### 标注问题
标注也是一个监督学习的问题. 可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测问题的简单形式

- 学习
- 标注

统计学习方法：
- 隐马尔可夫模型
- 条件随机场
